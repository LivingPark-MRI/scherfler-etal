{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Initial study\n",
    "\n",
    "This notebook identifies PPMI subjects to reproduce the following paper:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Scherfler, Christoph, et al. <a href=https://onlinelibrary.wiley.com/doi/pdf/10.1002/ana.22245>White and gray matter abnormalities in idiopathic rapid eye movement sleep behavior disorder: a diffusion‐tensor imaging and voxel‐based morphometry study.</a> Annals of neurology 69.2 (2011): 400-407. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This study recruited 34 patients with iRBD and confirmed iRBD diagnosis with polysomnography (PSG). Patients had no PD or dementia at time of MRI. The demographics parameters were as follows (table extracted from the paper):\n",
    "\n",
    "<img src=\"demographics.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the Python code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    \"\"\"<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the Python code.\"></form>\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 2022-07-13 13:10:01.966786\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"This notebook was run on {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture null\n",
    "!PIP_REQUIRE_VIRTUALENV=0  pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI cohort preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metadata download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's download the required metadata files from PPMI: \n",
    "* Age at visit\n",
    "* Demographics (to retrieve sex)\n",
    "* REM Sleep Behavior Disorder Questionnaire\n",
    "\n",
    "You will need to enter your PPMI username and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files are available: ['Age_at_visit.csv', 'Demographics.csv', 'REM_Sleep_Behavior_Disorder_Questionnaire.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import ppmi_downloader\n",
    "\n",
    "data_dir = \"data\"\n",
    "required_files = [\n",
    "    \"Age_at_visit.csv\",\n",
    "    \"Demographics.csv\",\n",
    "    \"REM_Sleep_Behavior_Disorder_Questionnaire.csv\",\n",
    "]\n",
    "\n",
    "missing_files = [x for x in required_files if not op.exists(os.path.join(data_dir, x))]\n",
    "\n",
    "if len(missing_files) > 0:\n",
    "    print(f\"Downloading missing files: {missing_files}\")\n",
    "    ppmi = ppmi_downloader.PPMIDownloader()\n",
    "    ppmi.download_metadata(\n",
    "        missing_files, destination_dir=data_dir, headless=False, timeout=600\n",
    "    )\n",
    "\n",
    "print(f\"The following files are available: {required_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need file `MRI_info.csv` produced by notebook https://github.com/LivingPark-MRI/ppmi-MRI-metadata. This file contains aggregate information about T1-weighted MRIs usable for VBM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/MRI_info.csv is available\n"
     ]
    }
   ],
   "source": [
    "file_path = op.join(\"data\", \"MRI_info.csv\")\n",
    "if not op.exists(file_path):\n",
    "    !(cd data && python -m wget \"https://raw.githubusercontent.com/LivingPark-MRI/ppmi-MRI-metadata/main/MRI metadata.ipynb\")  # use requests to improve portability\n",
    "    npath = op.join(\"data\", \"MRI metadata.ipynb\")\n",
    "    %run \"{npath}\"\n",
    "print(f\"File {file_path} is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## RBD Score computation\n",
    "\n",
    "The original study used polysomnographies to diagnose REM Sleep Behavior Disorder, however, this data is not available in PPMI.\n",
    "Instead, we will use the REM Sleep Behavior Disorder Screening Questionnaire [[1]](https://movementdisorders.onlinelibrary.wiley.com/doi/10.1002/mds.21740) to discriminate RBD patients from controls. This questionnaire consists of 13 yes/no questions that are aggregated to produce an RBD score on a scale of 13 points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the following distribution of RBD scores in the PPMI dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load PPMI RSBDQ data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(op.join(\"data\", \"REM_Sleep_Behavior_Disorder_Questionnaire.csv\"))\n",
    "\n",
    "# Compute and add RBDSQ score\n",
    "df[\"RBDSQ\"] = (\n",
    "    df[\"DRMVIVID\"]  # Q1\n",
    "    + df[\"DRMAGRAC\"]  # Q2\n",
    "    + df[\"DRMNOCTB\"]  # Q3\n",
    "    + df[\"SLPLMBMV\"]  # Q4\n",
    "    + df[\"SLPINJUR\"]  # Q5\n",
    "    + df[\"DRMVERBL\"]  # Q6.1\n",
    "    + df[\"DRMFIGHT\"]  # Q6.2\n",
    "    + df[\"DRMUMV\"]  # Q6.3\n",
    "    + df[\"DRMOBJFL\"]  # Q6.4\n",
    "    + df[\"MVAWAKEN\"]  # Q7\n",
    "    + df[\"DRMREMEM\"]  # Q8\n",
    "    + df[\"SLPDSTRB\"]  # Q9\n",
    "    + df[  # Q10\n",
    "        [\n",
    "            \"BRNINFM\",\n",
    "            \"DEPRS\",\n",
    "            \"EPILEPSY\",\n",
    "            \"HETRA\",\n",
    "            \"NARCLPSY\",\n",
    "            \"PARKISM\",\n",
    "            \"RLS\",\n",
    "            \"STROKE\",\n",
    "        ]\n",
    "    ].max(axis=1)\n",
    ")\n",
    "\n",
    "df[\"Q6\"] = df[\"DRMVERBL\"] + df[\"DRMFIGHT\"] + df[\"DRMUMV\"] + df[\"DRMOBJFL\"]\n",
    "\n",
    "# Note: CNSOTHCM isn't present in data\n",
    "\n",
    "# Check that max RBDSQ score is <= 13\n",
    "assert df[\"RBDSQ\"].max() <= 13\n",
    "\n",
    "df.groupby(\"RBDSQ\").count()[\"REC_ID\"].plot.bar()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.ylabel(\"Number of records\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filters\n",
    "\n",
    "Consistently with the original study, we only include subjects with no Parkinsonism. We include subjects in the RBD group when their RBD score is >= 5. We include subjects in the control group when their RBD score is < 5 and their score to Question 6 of the RBD Screening Questionnaire is 0 [**TODO** ref needed, see email thread between Madeleine and Ron Postuma].\n",
    "\n",
    "We obtain the following group sizes:\n",
    "\n",
    "<!-- and a cutoff score of 6 to identify RBD subjects among PD subjects, consistently with the results presented in [[2]](https://www.sciencedirect.com# /science/article/pii/S138994571100164X). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of RBD subjects: 742\n",
      "Number of control subjects: 1045\n"
     ]
    }
   ],
   "source": [
    "# Read demographics and MRI data.\n",
    "mri = pd.read_csv(op.join(\"data\", \"MRI_info.csv\"))[\n",
    "    [\"Subject ID\", \"Visit code\", \"Description\"]\n",
    "]\n",
    "mri.rename(columns={\"Subject ID\": \"PATNO\", \"Visit code\": \"EVENT_ID\"}, inplace=True)\n",
    "dem = pd.read_csv(op.join(\"data\", \"Demographics.csv\"))[[\"PATNO\", \"SEX\"]]\n",
    "age = pd.read_csv(op.join(\"data\", \"Age_at_visit.csv\"))\n",
    "\n",
    "# Merge RBD data with demographics, age and MRI\n",
    "merged = (\n",
    "    df.merge(dem, on=\"PATNO\", how=\"inner\")\n",
    "    .merge(age, on=[\"PATNO\", \"EVENT_ID\"], how=\"inner\")\n",
    "    .merge(mri, on=[\"PATNO\", \"EVENT_ID\"], how=\"inner\")[\n",
    "        [\"PATNO\", \"RBDSQ\", \"Q6\", \"SEX\", \"AGE_AT_VISIT\", \"Description\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract RBD subjects and controls according to inclusion criteria\n",
    "rbds = merged[merged[\"RBDSQ\"] >= 5].sort_values(by=\"PATNO\")\n",
    "controls = merged[(merged[\"RBDSQ\"] < 5) & (merged[\"Q6\"] == 0)].sort_values(by=\"PATNO\")\n",
    "\n",
    "print(f\"Number of RBD subjects: {len(rbds)}\")\n",
    "print(f\"Number of control subjects: {len(controls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cohort matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The RBD and control groups built previously give us a lot of flexibility to build a cohort that matches the one in the original study. We adopted the following approach:\n",
    "1. Randomly select 4 control women and 10 control men, to reproduce the F/M balance in the original paper\n",
    "2. Find 26 subjects from the RBD group that best match age and sex in the control group. We matched sex by direct sampling of males and females using the same proportion as in the original study. We matched age using a nearest-neighbor approach.\n",
    "\n",
    "We obtain the following cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def nn_match(sample1, df_2, n2, cat_variables, num_variables, random_state=0):\n",
    "    \"\"\"\n",
    "    Find len(sample1) rows in df_2 such that variables are matched with sample1.\n",
    "\n",
    "    sample1: samples in group1\n",
    "    df_2: dataframe with subjects in group 2\n",
    "    n2: desired sample size for group 2\n",
    "    cat_variables: categorical variables to match\n",
    "    num_variables: numerical variables to match\n",
    "    \"\"\"\n",
    "\n",
    "    def nn(x, df, variables):\n",
    "        \"\"\"\n",
    "        Find index of nearest neighbor of x in df\n",
    "\n",
    "        * x: a dataframe row\n",
    "        * df: a dataframe\n",
    "        * variables: variables to match. Should be normalized.\n",
    "        \"\"\"\n",
    "        df[\"dist\"] = sum((df[var] - x[var]) ** 2 for var in variables)\n",
    "        df.sort_values(\"dist\", inplace=True)\n",
    "        return df.head(1).index[\n",
    "            0\n",
    "        ]  ## there's probably a better way to do it but it works\n",
    "\n",
    "    # Check assumptions\n",
    "    n1 = len(sample1)\n",
    "    assert n1 <= n2\n",
    "    for v in num_variables + cat_variables:\n",
    "        assert v in sample1 and v in df_2\n",
    "\n",
    "    # Copy original dataframe to leave them untouched\n",
    "    df_2_ = df_2.copy()\n",
    "    sample1_ = sample1.copy()\n",
    "\n",
    "    # Normalize variables to match to compute meaningful distances\n",
    "    for v in num_variables:\n",
    "        m = df_2_[v].mean()\n",
    "        s = df_2_[v].std()\n",
    "        for df in (df_2_, sample1_):\n",
    "            df[v] = (df[v] - m) / s\n",
    "\n",
    "    # For each subject in sampled group 1,\n",
    "    # find one or more subject in sampled group 2, without replacement.\n",
    "    indices = []\n",
    "    for i in range(n2):\n",
    "        j = i % n1  # loop over sample1\n",
    "        df_2_cat = df_2_.copy()\n",
    "        for c in cat_variables:\n",
    "            df_2_cat = df_2_cat[df_2_cat[c] == sample1_.iloc[j][c]]\n",
    "        assert len(df_2_cat) > 0\n",
    "        index = nn(sample1_.iloc[j], df_2_cat, num_variables)\n",
    "        df_2_.drop(index=index, inplace=True)\n",
    "        indices.append(index)\n",
    "\n",
    "    sample2 = df_2[df_2.index.isin(indices)]\n",
    "\n",
    "    return sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly select 4 control women and 10 control men, to reproduce F/M balance in original paper\n",
    "controls = pd.concat(\n",
    "    [\n",
    "        controls[controls[\"SEX\"] == 0].sample(n=4, random_state=1),\n",
    "        controls[controls[\"SEX\"] == 1].sample(n=10, random_state=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Match with RBD subjects\n",
    "rbds = nn_match(controls, rbds, 26, [\"SEX\"], [\"AGE_AT_VISIT\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t| iRBD Patients\t| Controls\n",
      "Subjects, No. \t\t| 26 \t\t| 14\n",
      "F/M, No. \t\t| 8/18 \t\t| 4/10\n",
      "Age, mean +/- SD \t| 62.0 +/- 10.9 \t| 62.2 +/- 10.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\n",
    "    \"\\t\\t\\t| iRBD Patients\\t| Controls\"\n",
    "    + os.linesep\n",
    "    + f\"Subjects, No. \\t\\t| {len(rbds)} \\t\\t| {len(controls)}\"\n",
    "    + os.linesep\n",
    "    + f\"F/M, No. \\t\\t| {len(rbds[rbds['SEX']==0])}/{len(rbds[rbds['SEX']==1])} \\t\\t| {len(controls[controls['SEX']==0])}/{len(controls[controls['SEX']==1])}\"\n",
    "    + os.linesep\n",
    "    + f\"Age, mean +/- SD \\t| {round(rbds['AGE_AT_VISIT'].mean(),1)} +/- {round(rbds['AGE_AT_VISIT'].std(),1)} \\t| {round(controls['AGE_AT_VISIT'].mean(),1)} +/- {round(controls['AGE_AT_VISIT'].std(),1)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The demographics parameters of the selected PPMI subjects seem comparable to the ones in the initial study. By construction, gender balance is better in our cohort than in the original study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save patient ids\n",
    "pd.concat([controls[\"PATNO\"], rbds[\"PATNO\"]]).to_csv(\n",
    "    \"scherfler-etal-patnos.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image analysis\n",
    "\n",
    "Structural MRI analysis in the original paper is a straightforward VBM analysis implemented with SPM using the DARTEL toolbox. An excellent tutorial on VBM in SPM is available in https://www.fil.ion.ucl.ac.uk/~john/misc/VBMclass15.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imaging data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's download or update the DataLad dataset associated with this paper. This dataset contains:\n",
    "* MRI data for the selected subjects\n",
    "* Pre-computed analysis results\n",
    "LivingPark DataLad datasets are currently stored on `login.bic.mni.mcgill.ca`. This notebook assumes that you can ssh to this server and that you have configured DataLad in your account (see instructions [here](https://docs.google.com/document/d/1K7RzQjYC1O6tpSqe_c0CvxvJq38J10zNrDIdw20Yh_0/edit?usp=sharing)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Fetching updates for Dataset(/home/glatard/code/livingpark/scherfler-etal/.datalad) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge(ok): . (dataset) [Merged origin/master]\n",
      "update.annex_merge(ok): . (dataset) [Merged annex branch]\n",
      "update(ok): . (dataset)\n",
      "action summary:\n",
      "  merge (ok: 1)\n",
      "  update (ok: 1)\n",
      "  update.annex_merge (ok: 1)\n"
     ]
    }
   ],
   "source": [
    "import datalad\n",
    "import datalad.api as dat\n",
    "import os.path as op\n",
    "import io\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "# Download datalad dataset\n",
    "datalad_path = \".datalad\"  # local dataset name\n",
    "user = \"glatard\"  # username on login.bic.mni.mcgill.ca\n",
    "if op.exists(datalad_path):\n",
    "    d = dat.Dataset(datalad_path)\n",
    "    d.update(how=\"merge\")\n",
    "else:\n",
    "    dat.install(\n",
    "        source=f\"{user}@login.bic.mni.mcgill.ca:/data/pd/ppmi/livingpark-papers/scherfler-etal\",\n",
    "        path=datalad_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check if the subjects selected in our cohort are available in the DataLad dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available subjects: 2\n",
      "Number of missing subjects: 38\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"inputs\"\n",
    "\n",
    "subject_ids = list(controls.append(rbds)[\"PATNO\"])\n",
    "missing_subjects = [\n",
    "    x for x in subject_ids if not op.exists(op.join(dataset_name, f\"sub-{x}\"))\n",
    "]\n",
    "available_subjects = list(set(subject_ids) - set(missing_subjects))\n",
    "print(f\"Number of available subjects: {len(sorted(available_subjects))}\")\n",
    "print(f\"Number of missing subjects: {len(sorted(missing_subjects))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** In the future we will download the missing subjects, convert them to BIDS, and add them to DataLad dataset. For now we will just proceed with the available subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download missing subjects\n",
    "# import ppmi_downloader\n",
    "\n",
    "# ppmi = ppmi_downloader.PPMIDownloader()\n",
    "# ppmi.download_imaging_data(missing_subjects, headless=False, timeout=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1 images comes as .nii.gz files while SPM requires .nii files. Let's get the required images and uncompress them if not already done in the DataLad dataste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and uncompressed 0 T1 images (the other ones were already available in the DataLad dataset)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "\n",
    "def unzip(filename, output_filename):\n",
    "    with gzip.open(filename, \"rb\") as f_in:\n",
    "        os.makedirs(op.dirname(output_filename), exist_ok=True)\n",
    "        with open(output_filename, \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for s in available_subjects:\n",
    "    glob_expression = (\n",
    "        f\"{dataset_name}/sub-{s}/ses-1/anat/sub-{s}_ses-1_*run-01_T1w.nii.gz\"\n",
    "    )\n",
    "    for file_name in glob.glob(glob_expression):\n",
    "        output_filename = file_name.replace(\".gz\", \"\").replace(\n",
    "            dataset_name, op.join(\"outputs\", \"data\")\n",
    "        )\n",
    "        if not op.exists(output_filename):\n",
    "            count += 1\n",
    "            dat.get(file_name.replace(dataset_path, op.join(datalad_path, \"inputs\")))\n",
    "            unzip(file_name, output_filename)  # to make it usable in SPM\n",
    "print(\n",
    "    f\"Downloaded and uncompressed {count} T1 images (the other ones were already available in the DataLad dataset)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image processing consists of:\n",
    "1. Data pre-processing: segmentation, DARTEL template generation, normalization to MNI space\n",
    "2. Intra-cranial volume computation (to be used as covariates in the statistical model)\n",
    "3. Statistical model\n",
    "\n",
    "We implemented each of these steps as an SPM batch. For each batch, we created a template where file names will be inserted. Batch templates are available in `code/templates`.\n",
    "\n",
    "We generate a run id that uniquely identifies the cohort built previously. We will use this run id to avoid recomputing the same results multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: 3071741767022442618\n"
     ]
    }
   ],
   "source": [
    "run_id = str(hash(tuple(sorted(controls.append(rbds)[\"PATNO\"])))).replace(\n",
    "    \"-\", \"_\"\n",
    ")  # - in filenames crash SPM (Matlab)\n",
    "print(f\"Run id: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parametrize the pre-processing batch template using the subjects in the cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "\n",
    "def write_batch_files(batch_job_filename, replaced_keys, tempfile_name):\n",
    "    \"\"\"\n",
    "    tempfile_name: should end in _job.m\n",
    "    \"\"\"\n",
    "\n",
    "    def replace_keys(string, replace_keys):\n",
    "        for k in replace_keys:\n",
    "            string = string.replace(k, replace_keys[k])\n",
    "        return string\n",
    "\n",
    "    # Batch job file\n",
    "    with open(batch_job_filename, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    assert tempfile_name.endswith(\"_job.m\")\n",
    "\n",
    "    with open(tempfile_name, \"w\") as f:\n",
    "        f.write(replace_keys(content, replaced_keys))\n",
    "\n",
    "    print(f\"Job batch file written in {op.basename(tempfile_name)}\")\n",
    "\n",
    "    # Batch file\n",
    "    batch_file = op.join(\"code\", \"templates\", \"call_batch.m\")\n",
    "    tempfile_name_batch = tempfile_name.replace(\"_job\", \"_batch\")\n",
    "\n",
    "    with open(batch_file, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    with open(tempfile_name_batch, \"w\") as f:\n",
    "        f.write(\n",
    "            replace_keys(\n",
    "                content,\n",
    "                {\n",
    "                    \"[BATCH]\": f\"addpath('{op.join(os.getcwd(), 'code', 'batches')}')\"\n",
    "                    + os.linesep\n",
    "                    + op.basename(tempfile_name.replace(\".m\", \"\"))\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(f\"Batch file written in {op.basename(tempfile_name_batch)}\")\n",
    "\n",
    "\n",
    "def run_batch_file(job_filename):\n",
    "\n",
    "    log_file_name = op.abspath(\n",
    "        op.join(\"outputs\", \"logs\", op.basename(job_filename.replace(\"_job.m\", \".log\")))\n",
    "    )\n",
    "    spm_batch_file = job_filename.replace(\"_job\", \"_batch\")\n",
    "\n",
    "    if op.exists(log_file_name):\n",
    "        print(\n",
    "            f\"Log file {op.basename(log_file_name)} exists, skipping batch execution (remove file to force execution)\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    print(f\"Log file {op.basename(log_file_name)} does not exist, running batch\")\n",
    "\n",
    "    dat.unlock(\n",
    "        dataset=d\n",
    "    )  # unlock the dataset so that results can be overwritten if necessary\n",
    "    output = spm_batch(\n",
    "        \"launch\", \"-s\", \"-u\", spm_batch_file=spm_batch_file, log_file_name=log_file_name\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        output.exit_code == 0\n",
    "    ), f\"Execution error, inspect output object for logs: {output}\"\n",
    "\n",
    "    print(f\"Execution was successful.\")\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job batch file written in pre_processing_3071741767022442618_job.m\n",
      "Batch file written in pre_processing_3071741767022442618_batch.m\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "def subject_T1(subject_id):\n",
    "    expression = f\"{op.join('outputs', 'data')}/sub-{subject_id}/ses-1/anat/sub-{subject_id}_ses-1_*run-01_T1w.nii\"\n",
    "    file_names = glob.glob(expression)\n",
    "    assert (\n",
    "        len(file_names) == 1\n",
    "    ), f\"Zero or more than 1 files were matched by expression: {expression}\"\n",
    "    return file_names[0]\n",
    "\n",
    "\n",
    "# Preprocessing batch\n",
    "preprocessing_batch_job = op.join(\"code\", \"templates\", \"pre_processing_job.m\")\n",
    "preprocessing_name = op.abspath(\n",
    "    op.join(\"code\", \"batches\", f\"pre_processing_{run_id}_job.m\")\n",
    ")\n",
    "\n",
    "image_files = sorted([f\"'{op.abspath(subject_T1(s))},1'\" for s in available_subjects])\n",
    "write_batch_files(\n",
    "    preprocessing_batch_job,\n",
    "    {\"[IMAGES]\": os.linesep.join(image_files)},\n",
    "    tempfile_name=preprocessing_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the pre-processing batch. To ensure that it will run on this computer, we containerized it with Docker and wrapped it in a Boutiques descriptor. Let's run the batch. If it's the first time that you run this notebook, the Docker container will be downloaded to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file /home/glatard/code/livingpark/scherfler-etal/outputs/logs/pre_processing_3071741767022442618.log exists, skipping batch execution (remove file to force execution)\n"
     ]
    }
   ],
   "source": [
    "# Boutiques initialization for SPM batch\n",
    "from boutiques.descriptor2func import function\n",
    "\n",
    "spm_batch = function(\n",
    "    op.join(\"envs\", \"docker\", \"spm-batch.json\")\n",
    ")  # Use Octave 5.2.0 for DARTEL or it crashes\n",
    "\n",
    "output = run_batch_file(preprocessing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-cranial volume computation\n",
    "\n",
    "We compute intra-cranial volumes by (1) computing tissue volumes using the corresponding tool in SPM, (2) summing the grey-matter, white-matter, and CSF volumes. \n",
    "\n",
    "First, let's run the tissue volumes batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job batch file written in tissue_volumes_3071741767022442618_job.m\n",
      "Batch file written in tissue_volumes_3071741767022442618_batch.m\n",
      "Log file /home/glatard/code/livingpark/scherfler-etal/outputs/logs/tissue_volumes_3071741767022442618.log exists, skipping batch execution (remove file to force execution)\n"
     ]
    }
   ],
   "source": [
    "# Tissue volumes batch\n",
    "tissue_volumes_batch_job = op.join(\"code\", \"templates\", \"tissue_volumes_job.m\")\n",
    "volumes_name = preprocessing_name.replace(\"pre_processing\", \"tissue_volumes\")\n",
    "\n",
    "segmentation_files = sorted(\n",
    "    [x.replace(\".nii\", \"_seg8.mat\").replace(\",1\", \"\") for x in image_files]\n",
    ")\n",
    "volumes_file = op.abspath(\n",
    "    op.join(\"outputs\", op.basename(volumes_name.replace(\".m\", \".txt\")))\n",
    ")  # output file containing brain volumes\n",
    "write_batch_files(\n",
    "    tissue_volumes_batch_job,\n",
    "    {\n",
    "        \"[SEGMENTATION_FILES]\": os.linesep.join(segmentation_files),\n",
    "        \"[VOLUMES_FILE]\": volumes_file,\n",
    "    },\n",
    "    tempfile_name=volumes_name,\n",
    ")\n",
    "output = run_batch_file(volumes_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the following intra-cranial volumes (in litres):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.596575\n",
      "1.6336870000000001\n"
     ]
    }
   ],
   "source": [
    "# Read tissue volumes file\n",
    "\n",
    "import csv\n",
    "\n",
    "icvs = {}  # intra-cranial volumes per segmentation file\n",
    "\n",
    "\n",
    "def subject_id(segmentation_filename):\n",
    "    \"\"\"\n",
    "    Return subject id from segmentation file name\n",
    "    \"\"\"\n",
    "\n",
    "    sub_id = segmentation_filename.split(op.sep)[-4].replace(\"sub-\", \"\")\n",
    "    assert int(sub_id)\n",
    "    return sub_id\n",
    "\n",
    "\n",
    "with open(volumes_file) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        assert len(row) == 4, f\"Malformed row: {row}\"\n",
    "        icvs[subject_id(row[\"File\"])] = (\n",
    "            float(row[\"Volume1\"]) + float(row[\"Volume2\"]) + float(row[\"Volume3\"])\n",
    "        )\n",
    "\n",
    "for x in icvs:\n",
    "    print(icvs[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_batch = function(op.join(\"envs\", \"docker\", \"spm-batch.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job batch file written in stats_3071741767022442618_job.m\n",
      "Batch file written in stats_3071741767022442618_batch.m\n",
      "Log file /home/glatard/code/livingpark/scherfler-etal/outputs/logs/stats_3071741767022442618.log exists, skipping batch execution (remove file to force execution)\n"
     ]
    }
   ],
   "source": [
    "# Stats batch (grey matter)\n",
    "stats_batch_job = op.join(\"code\", \"templates\", \"stats_job.m\")\n",
    "stats_name = preprocessing_name.replace(\"pre_processing\", \"stats\")\n",
    "\n",
    "design_dir = op.join(\"outputs\", \"results\")\n",
    "os.makedirs(design_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def smwc1_scan(patno):\n",
    "    expression = f\"{op.join('outputs', 'data')}/sub-{patno}/ses-1/anat/smwc1sub-{patno}_ses-1_*run-01_T1w.nii\"\n",
    "    files = glob.glob(expression)\n",
    "    assert (\n",
    "        len(files) == 1\n",
    "    ), f\"Zero or more than 1 files were matched by expression: {expression}\"\n",
    "    return op.abspath(files[0])\n",
    "\n",
    "\n",
    "# Don't mess up with ordering, it's critical\n",
    "rbds_smwc1 = [\n",
    "    f\"'{smwc1_scan(patno)},1'\"\n",
    "    for patno in sorted(rbds[\"PATNO\"])\n",
    "    if patno in available_subjects\n",
    "]\n",
    "controls_smwc1 = [\n",
    "    f\"'{smwc1_scan(patno)},1'\"\n",
    "    for patno in sorted(controls[\"PATNO\"])\n",
    "    if patno in available_subjects\n",
    "]\n",
    "\n",
    "groups_patnos = [\n",
    "    x\n",
    "    for group in (rbds, controls)\n",
    "    for x in sorted(group[\"PATNO\"])\n",
    "    if x in available_subjects\n",
    "]\n",
    "all_subjects = pd.concat([rbds, controls])\n",
    "\n",
    "# Check orderding\n",
    "for i, x in enumerate(groups_patnos):\n",
    "    if i < len(rbds_smwc1):\n",
    "        assert f\"sub-{groups_patnos[i]}\" in rbds_smwc1[i]\n",
    "    else:\n",
    "        assert f\"sub-{groups_patnos[i]}\" in controls_smwc1[i - len(rbds_smwc1)]\n",
    "\n",
    "replace_keys = {\n",
    "    \"[DESIGN_DIR]\": op.abspath(design_dir),\n",
    "    \"[GROUP1_SMWC1_SCANS]\": os.linesep.join(rbds_smwc1),\n",
    "    \"[GROUP2_SMWC1_SCANS]\": os.linesep.join(controls_smwc1),\n",
    "    \"[ICVS]\": os.linesep.join(\n",
    "        [str(icvs[str(x)]) for x in groups_patnos if x in available_subjects]\n",
    "    ),  # don't mess up ordering\n",
    "    \"[AGES]\": os.linesep.join(\n",
    "        [\n",
    "            str(all_subjects[all_subjects[\"PATNO\"] == x][\"AGE_AT_VISIT\"].values[0])\n",
    "            for x in groups_patnos\n",
    "            if x in available_subjects\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Stats batch\n",
    "stats_batch_job = op.join(\"code\", \"templates\", \"stats_job.m\")\n",
    "stats_name = preprocessing_name.replace(\"pre_processing\", \"stats\")\n",
    "\n",
    "write_batch_files(stats_batch_job, replace_keys, tempfile_name=stats_name)\n",
    "output = run_batch_file(stats_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dat.Dataset(datalad_path)\n",
    "# dat.push(dataset=d)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
